{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bad09d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import faiss\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a63f678e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF created: sample.pdf\n"
     ]
    }
   ],
   "source": [
    "from fpdf import FPDF\n",
    "import unicodedata\n",
    "\n",
    "# Paragraph to repeat\n",
    "paragraph = (\n",
    "    \"Artificial Intelligence (AI) is transforming industries with its capabilities in \"\n",
    "    \"natural language processing, computer vision, and decision-making. From healthcare \"\n",
    "    \"diagnostics to financial forecasting and personalized education, AI applications are \"\n",
    "    \"expanding rapidly. The integration of large language models such as GPT-4 has revolutionized \"\n",
    "    \"the way machines understand and generate human language.\\n\\n\"\n",
    "    \"In healthcare, AI is aiding in early diagnosis of diseases, robotic surgeries, and personalized \"\n",
    "    \"treatment plans. In the financial sector, it is enabling better fraud detection, credit scoring, \"\n",
    "    \"and algorithmic trading. In education, AI tools are personalizing content to suit individual learning \"\n",
    "    \"styles, making learning more effective.\\n\\n\"\n",
    "    \"Ethical concerns remain, including data privacy, algorithmic bias, and the potential displacement \"\n",
    "    \"of jobs. Responsible AI development and policy regulations are crucial to mitigate these risks.\\n\\n\"\n",
    "    \"AIâ€™s future includes even more sophisticated models that can think, reason, and interact with the world \"\n",
    "    \"in human-like ways. With continued research and innovation, AI will continue to redefine what's possible \"\n",
    "    \"across all domains of life.\\n\\n\"\n",
    ")\n",
    "\n",
    "# Create the PDF\n",
    "pdf = FPDF()\n",
    "pdf.add_page()\n",
    "pdf.set_font(\"Arial\", size=12)\n",
    "\n",
    "for _ in range(25):  \n",
    "    clean_para = unicodedata.normalize(\"NFKD\", paragraph).encode(\"latin-1\", \"ignore\").decode(\"latin-1\")\n",
    "    pdf.multi_cell(0, 10, clean_para)\n",
    "\n",
    "# Save the file\n",
    "pdf.output(\"sample.pdf\")\n",
    "print(\"PDF created: sample.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cb5237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Loading and chunking document...\n",
      "[+] Embedding chunks and building FAISS index...\n",
      "[+] Retrieving top chunks for summary query...\n",
      "[+] Generating summary with LLM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== SUMMARY =====\n",
      "Artificial Intelligence (AI) is transforming industries with its capabilities in natural language processing, computer vision, and decision-making. From healthcare diagnostics to financial forecasting and personalized education, AI applications are expanding rapidly. Ethical concerns remain, including data privacy, algorithmic bias, and the potential displacement of jobs.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#loading and Chunk the Document \n",
    "def load_and_chunk_pdf(filepath, chunk_size=500, overlap=100):\n",
    "    doc = fitz.open(filepath)\n",
    "    text = \"\\n\".join(page.get_text() for page in doc)\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = \" \".join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "#embed and Store with FAISS \n",
    "def embed_chunks(chunks, model_name='all-MiniLM-L6-v2'):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    embeddings = model.encode(chunks)\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(np.array(embeddings))\n",
    "    return index, embeddings, chunks\n",
    "\n",
    "#Retrieve Top k Chunks \n",
    "def retrieve_top_k(query, model, index, chunks, k=5):\n",
    "    query_vec = model.encode([query])\n",
    "    distances, indices = index.search(np.array(query_vec), k)\n",
    "    return [chunks[i] for i in indices[0]]\n",
    "\n",
    "#summarizing Using LLM \n",
    "def summarize_chunks(chunks):\n",
    "    summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "    input_text = \"\\n\\n\".join(chunks)[:3000]  # Limit input length\n",
    "    summary = summarizer(input_text, max_length=200, min_length=50, do_sample=False)\n",
    "    return summary[0]['summary_text']\n",
    "\n",
    "def main():\n",
    "    filepath = \"sample.pdf\"  # Change this to your input file\n",
    "    print(\"[+] Loading and chunking document...\")\n",
    "    chunks = load_and_chunk_pdf(filepath)\n",
    "\n",
    "    print(\"[+] Embedding chunks and building FAISS index...\")\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    index, embeddings, chunks = embed_chunks(chunks)\n",
    "\n",
    "    print(\"[+] Retrieving top chunks for summary query...\")\n",
    "    top_chunks = retrieve_top_k(\"Summarize this document\", model, index, chunks)\n",
    "\n",
    "    print(\"[+] Generating summary with LLM...\")\n",
    "    summary = summarize_chunks(top_chunks)\n",
    "\n",
    "    print(\"\\n===== SUMMARY =====\")\n",
    "    print(summary)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0ce9fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
